\documentclass[10pt,a4paper]{article}
\usepackage[utf8x]{inputenc}
\usepackage{ucs}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}
\renewcommand\familydefault{\sfdefault}

\title{Summary - \lecture}
\author{}
\date{}


%costum layout
\setlength{\parindent}{0cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{
	\strut\rlap{\colorlayout\rule[-\dp\strutbox]{\headwidth}{\headheight}}
	\textcolor {white} {Summary: \lecture}}
\fancyfoot[L]{
	\strut\rlap{\colorlayout\rule[-\dp\strutbox]{\headwidth}{\headheight}}
	\textcolor {white} {last changed: \today}}
\fancyhead[R]{\textcolor{white}{\semseter}}
\fancyfoot[R]{\textcolor{white} {\thepage}}


%math
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{mathtools}


%graphics
\usepackage{graphicx}
\usepackage{floatflt}
\usepackage{float}


%tabular
\usepackage{tabularx}
\usepackage[font=small,labelfont=small]{caption}
\usepackage{colortbl}
\usepackage[dvipsnames]{xcolor}
\renewcommand{\arraystretch}{1}
%\arrayrulecolor{white}


%tikz
\usepackage{tikz}
\usetikzlibrary{shapes, petri}
\tikzstyle{ell}=[ellipse,draw, yshift=-2mm]
\tikzstyle{rec} = [rectangle, draw]
\tikzstyle{dia} = [diamond, aspect=2, draw, yshift=-5mm]
\tikzstyle{cir} = [circle, draw, minimum size=3mm]
\tikzstyle{arrHV} = [to path={-| (\tikztotarget)}]
\tikzstyle{arrVH} = [to path={|- (\tikztotarget)}]
\tikzstyle{whileright} = [xshift=20mm, yshift=-3mm]
\tikzstyle{whileleft} = [xshift=-20mm, yshift=-3mm]
\tikzstyle{txtright} = [above, xshift=15mm]
\tikzstyle{txtleft} = [above, xshift=-15mm]
\tikzstyle{empty} = [coordinate]
\usetikzlibrary{positioning}


%listings
\usepackage{listings}
\lstdefinestyle{costum} {
	language=Bash,
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\bfseries\color{cyan!50!blue},
	commentstyle=\itshape\color{black!50},
	%identifierstyle=\color{blue},
	stringstyle=\color{green!50!black},
	morekeywords={returns, loop, each},
	escapeinside={\%*}{*)}
}
\lstset{style=costum}


%custom title color
\usepackage{titlesec}
\setcounter{secnumdepth}{4}

\titleformat{\section}
{\color{cyan!80!blue}\normalfont\Large\bfseries}
{\color{cyan!80!blue}\thesection}{1em}{}

%\titleformat{\subsubsection}
%{\color{blue!30!black!70}\normalfont\bfseries}
%{\color{black}\thesection}{1em}{}
%
%\titleformat{\paragraph}
%{\color{green!30!black!70}\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
%\titlespacing*{\paragraph}
%{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}


%tab
\newcommand{\tab}[1][1]{\hspace*{#1cm}}


%hyperref
\usepackage{hyperref}


%vector
\newcommand{\vect}[1]{\ensuremath{\begin{bmatrix}#1\end{bmatrix}}}

\usepackage{pgfplots}

%TODO
%config
\newcommand{\lecture}{Introduction to Deep Learning} %title of the lecture
\newcommand{\lecturer}{Nießner M.} %lecturer of the lecture
\newcommand{\semseter}{summer semester 2020} %semester of this lecture, e.g., summer semester 2019
\newcommand{\colorlayout}{\color{cyan!50!blue}} %color of the title bar, see colors

%colors, e.g,
%cyan!50!blue
%green!50!black
%orange!50!black

%user
\newcommand{\cons}{\textcolor{red}{\textbf{\textendash}}}
\newcommand{\pros}{\textcolor{green}{\textbf{+}}}
\newcommand{\props}{$\circ$}

\newcommand{\icons}{\item[\cons]}
\newcommand{\ipros}{\item[\pros]}
\newcommand{\iprops}{\item[\props]}


%TODO
%FINISHED Lecture Chapter:
%Chap 1: cc
%Chap 2: cc
%Chap 3: cc
%Chap 4: cc
%Chap 5: cc
%Chap 6: cc
%Chap 7: cc
%Chap 8: cc
%Chap 9: cc
%Chap 10: cc
%Chap 11: cc
%Chap 12: x

%FINISHED Summary Chapter
%Chap Machine Learning Basics: cf
%Chap Linear Models: cf
%Chap Computational Graphs: cf
%Chap Neural Network: f
%Chap FCNN: cf
%Chap Conv NN:
%Chap Training:



\begin{document}
\tableofcontents
\pagebreak

\section{Machine Learning Basics}
\subsection{Un-/Supervised Learning}
\begin{itemize}
	\item Unsupervised Learning
	\begin{itemize}
		\item No label or target class
		\item Find out properties of the structure of the data
		\item Clustering (k-means, PCA, etc.)
	\end{itemize}
	\item Supervised Learning
	\begin{itemize}
		\item Labels or target classes
	\end{itemize}
	\item Reinforcement Learning
\end{itemize}

\subsection{Common Performance Metrics}
\begin{itemize}
	\item \textbf{Top-1 score:} Check if a sample's top class (i.e., the one with the highest probability) is the same as its target label
	\item \textbf{Top-5 score:} Check if your label is in your 5 first predictions (i.e. predictions with 5 highest probabilities)
	\item \textbf{Top-5 error:} Percentage of test samples for which the correct class was not in the top 5 predicted classes
\end{itemize}

\pagebreak
\section{Linear Models}
\subsection{Regression, Classification}
\begin{itemize}
	\item \textbf{Regression:} Predicts a continuous output value
	\item \textbf{Classification:} Predicts a discrete value
	\begin{itemize}
		\item \textbf{Binary Classification:} Output either $0$ or $1$
		\item \textbf{Multi-class classification:} Set of N classes
	\end{itemize}
\end{itemize}

\subsection{Linear Regression}
\subsubsection{Linear Model}
\begin{tabular}{ll}
	$i$: & Index of current sample \\
	$j$: & Index of current weight \\
	$d$: & Input dimension/number of weights \\
	$x_{ij}$: & $i$-th Input data/feature of the $j$-th weight \\
	$\theta_0$: & Bias \\
	$\theta_j$: & Weights \\
	$\hat y_i$: & $i$-th Prediction/Estimation (predicted label)
\end{tabular}

$$
	\hat y_i = \theta_0 + \sum_{j = 1}^d x_{ij} \theta_j = \theta_0 + x_{i1} \theta_1 + \dots + x_{id} \theta_d
$$

\textbf{Matrix Notation:}
$$
	\hat y = X \theta
$$

\subsubsection{Loss function}
Measures how good my estimation is and tells the optimization method how to make it better

\paragraph{Linear Least Squares:} ~\\
\begin{tabular}{ll}
	$n$: & Number of training samples \\
	$y$: & Ground truth labels \\
	$\hat y$: & Estimated labels
\end{tabular}
$$
	J(\theta) = \frac 1 n \sum_{i = 1}^n (\hat y_i - y_i)^2
$$

\textbf{Matrix Notation:}
$$
	J(\theta) = (X \theta - y)^T (X \theta - y) = (\hat y - y)^T (\hat y - y)
$$

\subsubsection{Optimization}
Changes the model in order to improve the loss function/estimation:
$$
	\theta = (X^TX)^{-1}X^Ty
$$

\subsection{Logistic Regression}
\subsubsection{Model}
\begin{tabular}{ll}
	$i$: & Index of current sample \\
	$j$: & Index of current weight \\
	$d$: & Input dimension/number of weights \\
	$x_{ij}$: & $i$-th Input data/feature of the $j$-th weight \\
	$\theta_j$: & Model parameters (Bias + Weights)\\
	$\hat y_i$: & $i$-th Prediction/Estimation (predicted label)
\end{tabular}

$$
	\hat y_i = \sigma(x_i \theta) = \sigma \left(\theta_0 + \sum_{j = 1}^d x_{ij} \theta_j \right)
$$
with
$$
	\sigma(x) = \frac 1 {1 + e^{-x}}
$$

\subsubsection{Loss function}
Measures how good my estimation is and tells the optimization method how to make it better

\paragraph{Binary Cross-Entropy:} ~\\
\begin{tabular}{ll}
	$y$: & Ground truth labels \\
	$\hat y$: & Estimated labels
\end{tabular}
$$
	\mathcal L(\hat y_i, y_i) = y_i \log \hat y_i + (1 - y_i) \log (1 - \hat y_i)
$$

\subsubsection{Cost function}
\begin{tabular}{ll}
	$n$: & Number of labels
\end{tabular}
$$
	C(\theta) = - \frac 1 n \sum_{i = 1}^n \mathcal L(\hat y_i, y_i)
$$

\subsubsection{Optimization}
Changes the model in order to improve the loss function/estimation
\begin{itemize}
	\item No closed-form solution
	\item Make use of an iterative method e.g. Gradient Descent
\end{itemize}


\pagebreak
\section{Computational Graphs}
\begin{itemize}
	\item Directional graph
	\item Matrix operations are represented as compute nodes
	\item Vertex nodes are variables or operators like $+, -, ⋅, /, log(), exp(), \dots$
	\item Directional edges show flow of inputs to vertices
	\item Neural network can be represented as computational graph
\end{itemize}

\subsection{Graphical representation}
\textbf{Example}
$$
	f(x, y, z) = (x + y) ⋅ z
$$
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/comp_graph.png}
\end{figure}

\textbf{Neural Network as Computational Graph}
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/comp_graph_nn.png}
\end{figure}


\pagebreak
\section{Neural Network}
\subsection{Activation Functions}

\textbf{Parameters:} \\
\begin{tabular}{ll}
	$\hat y$: & Prediction \\
	$\hat y_j$: & Prediction of $j$-th output ($j$-th Neuron of output layer) \\
	$h$: & Outputs of hidden layer \\
	$s$: & Output of layer (before activation) \\
	$s_j$: & Output of the $j$-th neuron in layer (before activation) \\
	$C$: & Number of classes (number of neurons in output layer)
\end{tabular}

\subsubsection{Sigmoid}
\begin{itemize}
	\item Used for Binary Classification to output a probability matching first or second class
	\iprops Output: $\hat y = (0, 1)$
	\iprops If used as activation function in hidden layer (typically it is not)
	\begin{itemize}
		\item[\cons] Output is always positive
		\item[\cons] Saturates for high positive or low negative values → kills the gradient flow
	\end{itemize}	
\end{itemize}
\begin{tabularx}{\columnwidth}{XX}
	$$
	\sigma(s) = \frac 1 {1 + e^{-s}}
	$$ &\\&
	
	\begin{tikzpicture}
	\begin{axis}[
	xmin=-10, xmax=10,
	ymin=-0, ymax=1,
	axis y line=middle,
	axis x line=middle,
	]
	\addplot+[domain=-10:10, samples=100, mark=none] {1/(1 + exp(-x))};
	\end{axis}
	\end{tikzpicture}
\end{tabularx}

\subsubsection{Softmax}
\begin{itemize}
	\item Used for Multiclass Classification to output a probability matching the $i$-th class
	\iprops Output: $\hat y_j = (0, 1)$
\end{itemize}

$$
	\hat y_j = \frac{e^{s_j}}{\sum_{k = 1}^{C} e^{s_k}}
$$


\subsubsection{Tanh (Hyperbolic Tanjant Function)}
\begin{itemize}
	\ipros Zero-centered
	\item[\cons] Saturates for high positive or low negative values → kills the gradient flow
\end{itemize}

\begin{tabularx}{\columnwidth}{XX}	
	$$
		h = \tanh(s)
	$$ &\\&
	
	\begin{tikzpicture}
	\begin{axis}[
	xmin=-10, xmax=10,
	ymin=-1, ymax=1,
	axis y line=middle,
	axis x line=middle,
	]
	\addplot+[domain=-10:10, samples=100, mark=none] {tanh(x)};
	\end{axis}
	\end{tikzpicture}
\end{tabularx}

\subsubsection{ReLU (Rectified Linear Units)}
\begin{itemize}
	\iprops Standard choice for activation function
	\item[\pros] Does not saturate
	\item[\pros] Large and consistent gradients
	\item[\pros] Fast convergence
	\item[\cons] Dead ReLU if output is zero
	\iprops Initialization of ReLU neurons with slightly positive biases (e.g. $0.01$) → Likely to stay active for most inputs
\end{itemize}

\begin{tabularx}{\columnwidth}{XX}	
	$$
		h = \max(0, s)
	$$ &\\&
	
	\begin{tikzpicture}
	\begin{axis}[
	xmin=-10, xmax=10,
	ymin=0, ymax=10,
	axis y line=middle,
	axis x line=middle,
	]
	\addplot+[domain=-10:10, samples=100, mark=none] {max(0,x)};
	\end{axis}
	\end{tikzpicture}
\end{tabularx}

\subsubsection{Leaky ReLU}
\begin{itemize}
	\item[\pros] Does not die
\end{itemize}

\begin{tabularx}{\columnwidth}{XX}	
	$$
		h = \max(0.01s, s)
	$$ &\\&
	
	\begin{tikzpicture}
	\begin{axis}[
	xmin=-10, xmax=10,
	ymin=-1, ymax=10,
	axis y line=middle,
	axis x line=middle,
	]
	\addplot+[domain=-10:10, samples=100, mark=none] {max(0.01*x,x)};
	\end{axis}
	\end{tikzpicture}
\end{tabularx}

\subsubsection{Parametric ReLU}
\begin{itemize}
	\iprops $\alpha$ is a learnable parameter
	\item[\pros] Does not die
\end{itemize}

$$
	h = \max(\alpha s, s)
$$

\subsubsection{ELU}
$$
f(s) = \begin{cases}
s & \text{if } s > 0 \\
\alpha (e^s - 1) & \text{if } s ≤ 0
\end{cases}
$$

\subsubsection{Maxout}
\begin{itemize}
	\item[\pros] Generalization of ReLUs
	\item[\pros] Linear regimes
	\item[\pros] Does not die
	\item[\pros] Does not saturate
	\item[\cons] Increases the number of parameters
\end{itemize}
$$
 	h = \max(w_1^Ts + b_1, w_2^T s + b_2)
$$

\subsubsection{Step Function}
\begin{tabularx}{\columnwidth}{XX}	
	$$
		h = \begin{cases}
			0 & \text{if } s < 0 \\
			1 & \text{if } s ≥ 0 \\
		\end{cases}
	$$ &\\&
	
	\begin{tikzpicture}
	\begin{axis}[
	xmin=-10, xmax=10,
	ymin=-1, ymax=2,
	axis y line=middle,
	axis x line=middle,
	]
	\addplot+[blue, domain=-10:0, samples=100, mark=none] {0};
	\addplot+[blue, domain=0:10, samples=100, mark=none] {1};
	\end{axis}
	\end{tikzpicture}
\end{tabularx}


\subsection{Loss Function}
\subsubsection{Description}
\begin{itemize}
	\item A function to measure the goodness of the predictions
	\item Goal: Minimize the loss $\iff$ Find better predictions
	\item[\props] Large loss $\implies$ bad predictions	
	\iprops Choice of the loss function depends on the concrete problem or the distribution of the target variable
\end{itemize}

\subsubsection{Parameters}
\begin{tabular}{ll}
	$y_i$: & Ground truth of $i$-th sample \\
	$\hat y_i$: & Prediction of $i$-th sample \\
	$n$: & number of training samples \\
	$k$: & number of classes \\
	$\hat y_{i, gt}$: & Prediction of ground truth class of $i$-th sample (where $y_{ij} = 1$)
\end{tabular}

\subsubsection{L1 Loss}
\begin{itemize}
	\item Sum of absolute differences
	\item[\props] Optimum is the median
	\item[\props] Robust (cost of outliers is linear)
	\item[\cons] Costly to optimize
	
\end{itemize}
$$
	\mathcal L(y, \hat y; \theta) = \frac 1 n \sum_i^n ||y_i - \hat y_i||_1
$$

\subsubsection{L2/MSE Loss}
\begin{itemize}
	\item Sum of squared differences
	\item[\props] Optimum is the mean
	\item[\props] Prone to outliers
	\item[\pros] Compute-efficient optimization
	
\end{itemize}
$$
	\mathcal L(y, \hat y; \theta) = \frac 1 n \sum_i^n ||y_i - \hat y_i||_2^2
$$

\subsubsection{Binary Cross Entropy}
$$
	\mathcal L(y, \hat y; \theta) = - \frac 1 n \sum_{i = 1}^n (y_i \log \hat y_i + (1 - y_i) \log(1 - \hat y_i))
$$

\subsubsection{Cross Entropy}
\begin{itemize}
	\iprops Loss is typically always $> 0$ → Always improvement
\end{itemize}
$$
	\mathcal L(y, \hat y; \theta) = - \frac 1 n \sum_{i = 1}^n \sum_{j = 1}^k (y_{ij} \log \hat y_{ij})
$$

\subsubsection{Hinge Loss (SVM Loss)}
\begin{itemize}
	\iprops Loss can become $= 0$ → Saturation
\end{itemize}
$$
	\mathcal L(y, \hat y; \theta) = \frac 1 n \sum_{i = 1}^n \sum_{{j = 1,} \atop {j ≠ gt}}^k \max(0, \hat y_{ij} - \hat y_{i,gt} + 1)
$$


\subsection{Optimization Functions}
Changes the model in order to improve the loss function/estimation
\subsubsection{General Optimization}
\begin{itemize}
	\item \textbf{Goal:} $\theta^* = \arg\min f(\theta, x, y)$
	\item \textbf{Linear Systems (Ax = b)}
	\begin{itemize}
		\item LU, QU, Cholesky, Jacobi, Gauss-Seidel, CG, PCG, ...
	\end{itemize}
	\item \textbf{Non-linear systems} (Gradient based methods):
	\begin{itemize}
		\item First order methods:
		\begin{itemize}
			\item Gradient Descent, SGD, SGD with Momemtum, RMSProp, Adam (Standard)
		\end{itemize}
		\item Second order methods (faster than first order methods, but only for full batch updates):
		\begin{itemize}
			\item Newton, Gauss-Newton, Levenberg-Marquardt, (L)BFGS
		\end{itemize}
	\end{itemize}
\end{itemize}


\subsubsection{Gradient Descent}
\begin{itemize}
	\item Finds local minimum
	\item Does gradient steps in direction of negative gradient
	\iprops Does not guarantee to find global optimum
	\item[\cons] Requires a lot of memory $\implies$ extremely expensive
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$f(\theta, x_{1..n}, y_{1..n})$: & Function describing the neural network (including loss function) \\
	$x_{1..n}$: & Input vectors for all $n$ training samples \\
	$y_{1..n}$: & Ground truth for all $n$ training samples \\
	$\theta^k = \{W, b\}$: & Model Parameters at step $k$ \\
	$\alpha$: & Learning rate
\end{tabular} \\

Gradient Step:
$$
	\theta^{k + 1} = \theta^k - \alpha \nabla_\theta f(\theta^k, x_{1..n}, y_{1..n})
$$

\subsubsection{Stochastic Gradient Descent}
\begin{itemize}
	\item Split training set into several minibatches
	\item Minibatch size:
	\begin{itemize}
		\item Is a hyperparameter
		\item Is typically a power of 2
		\item Smaller batch size $\implies$ Greater variance in the gradients
		\item Is mostly limited by GPU memory
	\end{itemize}
	\iprops Epoch: Complete pass through training set
	\item[\cons] Cannot independently scale directions
	\item[\cons] Need to have conservative min learning rate to avoid divergence
	\item[\cons] Is slower than necessary
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$n$: & Number of total training samples \\
	$m$: & Minibatch size (number of training samples per minibatch) \\
	$n/m$: & Number of minibatches \\
	$f(\theta, x_{1..m}, y_{1..m})$: & Function describing the neural network (including loss function) \\
	$x_{1..m}$: & Input vectors for one minibatch \\
	$y_{1..m}$: & Ground truth for one minibatch \\
	$\theta^k = \{W, b\}$: & Model Parameters at iteration $k$\\
	$k$: & Iteration in current epoch \\
	$\alpha$: & Learning rate
\end{tabular} \\

Gradient Step:
$$
	\theta^{k + 1} = \theta^k - \alpha \nabla_\theta f(\theta^k, x_{1..m}, y_{1..m})
$$

\paragraph{Convergence of Stochastic Gradient Descent} ~\\
$f(\theta, x, y)$ converges to a local (global) minimum if:
\begin{enumerate}
	\item $\alpha_n ≥ 0, \forall n ≥ 0$
	\item $\sum_{n = 1}^∞ \alpha_n = ∞$
	\item $\sum_{n = 1}^∞ \alpha_n^2 < ∞$
	\item $f(\theta, x, y)$ ist strictly convex
\end{enumerate}
where $\alpha_1, \dots, \alpha_n$ is a sequence of positive step-sizes

\subsubsection{Gradient Descent with Momentum}
\begin{itemize}
	\item Step will be largest when a sequence of gradients all point to the same direction
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$f(\theta, x, y)$: & Function describing the neural network (including loss function) \\
	$x$: & Input vectors \\
	$y$: & Ground truth \\
	$\theta^k = \{W, b\}$: & Model Parameters at step $k$\\
	$\alpha$: & Learning rate \\
	$\beta$: & Accumulation rate (friction, momentum), default: 0.9 \\
	$v^k$: & Velocity at step $k$ \\
\end{tabular} \\

Gradient step:
$$
	v^{k + 1} = \beta ⋅ v^k - \alpha ⋅ \nabla_\theta f(\theta^k, x, y)
$$
$$
	\theta^{k + 1} = \theta^k + v^{k + 1}
$$

\subsubsection{Nesterov Momentum}
\begin{itemize}
	\item Look-ahead momentum
	\item Steps:
	\begin{enumerate}
		\item Make a big jump in the direction of the previous accumulated gradient
		\item Measure the gradient where you end up
		\item Make a correction
	\end{enumerate}
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$f(\theta, x, y)$: & Function describing the neural network (including loss function) \\
	$x$: & Input vectors \\
	$y$: & Ground truth \\
	$\theta^k = \{W, b\}$: & Model Parameters at step $k$\\
	$\alpha$: & Learning rate \\
	$\beta$: & Accumulation rate (friction, momentum), default: 0.9 \\
	$v^k$: & Velocity at step $k$ \\
\end{tabular} \\

Gradient step:
$$
	\tilde \theta^{k + 1} = \theta^k + \beta ⋅ v^k
$$
$$
	v^{k + 1} = \beta ⋅ v^k - \alpha ⋅ \nabla_\theta f(\tilde \theta^{k + 1}, x, y)
$$
$$
	\theta^{k + 1} = \theta^k + v^{k + 1}
$$

\subsubsection{Root Mean Squared Prop (RMSProp)}
\begin{itemize}
	\item Divides the learning rate by an exponentially-decaying average of squared gradients
	\item Damps the oscillations for high-variance directions
	\item[\pros] Can increase learning rate because it is less likely to diverge → Speeds up learning speed
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$f(\theta, x, y)$: & Function describing the neural network (including loss function) \\
	$x$: & Input vectors \\
	$y$: & Ground truth \\
	$\theta^k = \{W, b\}$: & Model Parameters at step $k$\\
	$\alpha$: & Learning rate \\
	$\beta$: & Accumulation rate (friction, momentum), default: $0.9$ \\
	$\epsilon$: & Prevents division by zero, default: $10^{-8}$ \\
	$s^k$: & Second momentum (uncentered variance of gradients)
\end{tabular} \\

Gradient step:
$$
	s^{k + 1} = \beta ⋅ s^k + (1 - \beta)(\nabla_\theta f(\theta^k, x, y) \circ \nabla_\theta f(\theta^k, x, y))
$$
$$
	\theta^{k + 1} = \theta^k - \alpha ⋅ \frac{\nabla_\theta f(\theta^k, x, y)}{\sqrt{s^{k + 1}} + \epsilon}
$$
where $a \circ b$ is an element-wise multiplication

\subsubsection{Adaptive Momemt Estimation (Adam)}
\begin{itemize}
	\item Combines Momentum and RMSProp
	\item Combines first and second order momentum
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$f(\theta, x, y)$: & Function describing the neural network (including loss function) \\
	$x$: & Input vectors \\
	$y$: & Ground truth \\
	$\theta^k = \{W, b\}$: & Model Parameters at step $k$\\
	$\alpha$: & Learning rate \\
	$\beta_1$: & Accumulation rate 1, default: $0.9$ \\
	$\beta_2$: & Accumulation rate 2, default: $0.999$ \\
	$\epsilon$: & Prevents division by zero, default: $10^{-8}$ \\
	$s^k$: & Second momentum (uncentered variance of gradients)
\end{tabular} \\

Gradient step:
$$
	\hat m^{k + 1} = \frac{\beta_1 ⋅ m^k + (1 -\beta_1) ⋅ \nabla_\theta f(\theta^k, x, y)}{1 - \beta_1^{k + 1}}
$$
$$
	\hat v^{k + 1} = \frac{\beta_2 ⋅ v^k + (1 - \beta_2)(\nabla_\theta f(\theta^k, x, y) \circ \nabla_\theta f(\theta^k, x, y))}{1 - \beta_2^{k + 1}}
$$
$$
	\theta^{k + 1} = \theta^k - \alpha ⋅ \frac{\hat m^{k + 1}}{\sqrt{\hat v^{k + 1}} + \epsilon}
$$
where $m^0 = v^0 = 0$

\subsubsection{Newton's Method}
\begin{itemize}
	\iprops Computation complexity of inversion per iteration: $\mathcal O(k^3)$
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$f(\theta)$: & Function describing the neural network (including loss function) \\
	$\theta = \{W, b\}$: & Model Parameters \\
	$\nabla_\theta f(\theta)$: & Gradient (first derivative) \\
	$H(\theta)$: & Hessian matrix (second derivative)
\end{tabular} \\

Approximate the function by a second-order Taylor series expansion
$$
	f(\theta) \approx f(\theta_0) + (\theta - \theta_0)^T \nabla_\theta f(\theta_0) + \frac 1 2 (\theta - \theta_0)^T H(\theta - \theta_0)
$$

Update step:
$$
	\theta^* = \theta_0 - H^{-1} \nabla_\theta f(\theta)
$$

\subsubsection{Broyden-Fletcher-Goldfarb-Shanno algorithm (BFGS and L-BFGS)}
\begin{itemize}
	\item[\props] Belongs to the family of quasi-Newton methods
	\iprops Have an approximation of the inverse of the Hessian
	\iprops Computation complexity of inversion per iteration:
	\begin{itemize}
		\item BFGS: $\mathcal O(n^2)$
		\item L-BFGS: $\mathcal O(n)$
	\end{itemize}
\end{itemize}

Update step:
$$
	\theta^* = \theta_0 - H^{-1} \nabla_\theta f(\theta)
$$

\subsubsection{Gauss-Newton}
\begin{itemize}
	\item Approximates 2nd derivatives since there are often hard to obtain
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$\theta = \{W, b\}$: & Model Parameters \\
	$\nabla_\theta f(\theta)$: & Gradient (first derivative) \\
	$\mathcal J(\theta)$: & Jacobian matrix
\end{tabular} \\

$$
	H(\theta) \approx 2 \mathcal J^T(\theta) \mathcal J(\theta)
$$

Linear equation:
$$
	2(\mathcal J^T(\theta_k) \mathcal J(\theta_k)) ⋅ (\theta_k - \theta_{k + 1}) = \nabla_\theta f(\theta)
$$
	

\subsubsection{Levenberg}
\begin{itemize}
	\item Damped version of Gauss-Newton
	\item Damping factor is adjusted in each iteration, so that: $f(\theta_k) > f(\theta_{k + 1})$
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$\theta = \{W, b\}$: & Model Parameters \\
	$\nabla_\theta f(\theta)$: & Gradient (first derivative) \\
	$\mathcal J(\theta)$: & Jacobian matrix \\
	$\lambda$: & Damping factor
\end{tabular} \\

Linear equation:
$$
	(\mathcal J^T(\theta_k) \mathcal J(\theta_k) + \lambda I) ⋅ (\theta_k - \theta_{k + 1}) = \nabla_\theta f(\theta)
$$

\subsubsection{Levenberg-Marquardt}
\begin{itemize}
	\item Scales each component of the gradient according to the curvature
	\ipros Avoids slow convergence in components with a small gradient
\end{itemize}

Parameters: \\
\begin{tabular}{ll}
	$\theta = \{W, b\}$: & Model Parameters \\
	$\nabla_\theta f(\theta)$: & Gradient (first derivative) \\
	$\mathcal J(\theta)$: & Jacobian matrix \\
	$\lambda$: & Damping factor
\end{tabular} \\

Linear equation:
$$
	(\mathcal J^T(\theta_k) \mathcal J(\theta_k) + \lambda ⋅ \textrm{diag}(\mathcal J^T(\theta_k) \mathcal J(\theta_k))) ⋅ (\theta_k - \theta_{k + 1}) = \nabla_\theta f(\theta)
$$

\subsection{Learning rate}
\begin{itemize}
	\item Goal: High learning rate in the beginning, then low learning rate
\end{itemize}

\subsubsection{Learning Rate Decay}
\begin{tabular}{ll}
	$\alpha_0$: & Initial learning rate (e.g. 0.1) \\
	$t$: & Factor by which the learning rate is decayed \\
	$epoch$: & Epoch of current run
\end{tabular} \\

\textbf{Learning rate decays:}
$$
	\alpha = \frac 1 {1 + t ⋅ epoch} ⋅ \alpha_0, \tab \text{default: } t = 0.1
$$

Step decay:
$$
	\alpha = \alpha - t ⋅ \alpha, \tab \text{default: } t = 0.5
$$

Exponential decay:
$$
	\alpha = t^{epoch} ⋅ \alpha_0, \tab t < 1.0
$$

$$
	\alpha = \frac t {\sqrt{epoch}} ⋅ \alpha_0
$$

\subsubsection{Training Schedule}
\begin{itemize}
	\item Manually set learning rate every n epochs
\end{itemize}




\subsection{Regularization Techniques}
\begin{itemize}
	\item Increasing training error
	\item Lower validation error
\end{itemize}

\subsubsection{L1/L2 Regularization}
\begin{tabular}{ll}
	$L$: & Loss \\
	$\mathcal L (y, \hat y, \theta)$: & Loss function (without generalization) \\
	$\lambda$: & Regularization rate \\
	$\theta = \{W, b\}$: & Model parameters	
\end{tabular} \\

Add regularization term to loss function:
$$
	L = \mathcal L(y, \hat y, \theta) + \lambda R(\theta)
$$

\textbf{L1 Regularization} \\
Enforces sparsity
$$
	R(\theta) = \sum_{i = 1}^n |\theta_i|
$$

\textbf{L2 Regularization} \\
Enforces that the weights have similar values
$$
	R(\theta) = \sum_{i = 1}^n \theta_i^2
$$

\subsubsection{Weight Decay}
\begin{itemize}
	\iprops Penalizes large weights
	\iprops Improves generalization
\end{itemize}
Parameters: \\
\begin{tabular}{ll}
	$f(\theta, x_{1..n}, y_{1..n})$: & Function describing the neural network (including loss function) \\
	$x_{1..n}$: & Input vectors for all $n$ training samples \\
	$y_{1..n}$: & Ground truth for all $n$ training samples \\
	$\theta^k = \{W, b\}$: & Model Parameters at step $k$ \\
	$\alpha$: & Learning rate \\
	$\lambda$: & Regularization rate \\
	$R(\theta^k)$: & L2 Regularization
\end{tabular} ~\\

Add regularization term to Gradient step:
$$
	\theta^{k + 1} = \theta^k - \alpha \nabla_\theta f(\theta^k, x_{1..n}, y_{1..n}) - \lambda R(\theta^k)
$$

\subsubsection{Early Stopping}
Stop training as soon as the model begins overfitting

\subsubsection{Bagging and Ensemble Methods}
\begin{itemize}
	\item Train multiple models and average their results
	\item Use different optimization functions, loss functions, ... for each model
	\item[\pros] If errors are uncorrelated, the expected combined error will decrease linearly with the ensemble size
\end{itemize}
	

\subsubsection{Dropout}
\begin{itemize}
	\item Disable a random set of neurons with probability $p$ (default: $p = 50 \%$)
	\iprops Intuition: Use half of the network:
	\begin{itemize}
		\item[→] Redundant representations
		\item[→] Base your scores on more features
		\item[→] Reducing co-adaptations between neurons
	\end{itemize}
	\item Testing:
	\begin{itemize}
		\item Disable dropout (all neurons are turned on)
		\item Multiply with dropout probability: $s_j' = s_j ⋅ p$
	\end{itemize}
	\icons Reduces the effective capacity of a model → More training time
\end{itemize}

\subsubsection{Batch Normalization (BN)}
\begin{itemize}
	\item Goal: Activations do not die out
	\item Normalizes the mean and the variance of the inputs to the activation functions
	\item Is applied after Fully Connected (or Convolutional) Layers and before non-linear activation functions
	\ipros Very deep nets are much easier to train → more stable gradients
	\iprops Can be undone by the network with: $\gamma^{(k)} = \sqrt{Var[s^{(k)}]}, \beta^{(k)} = \mathbb E[s^{(k)}]$
	\iprops All biases of the layers before BN can be set to zero, since they will be canceled out by BN anyway
	\item Testing:
	\begin{itemize}
		\item Compute mean $\mu_{test}$ and variance $\sigma^2_{test}$ by running an exponentially weighted averaged across training minibatches: \\
		$Var_{running} = \beta_m ⋅ Var_{running} + (1 - \beta_m) ⋅ Var_{minibatch}$ \\
		$\mu_{running} = \beta_m ⋅ \mu_{running} + (1 - \beta_m) ⋅ \mu_{minibatch}$ \\
	\end{itemize}
\end{itemize}

\textbf{Parameters:} \\
\begin{tabular}{ll}
	$s^k$: & Output of the Fully Connected or Convolutional Layer before the Batch Normalization Layer \\
	$\mathbb{E}[s^k]$: & Mean of the mini-batch examples over feature k \\
 	$Var[s^k]$: & Variance of the mini-batch examples over feature k \\
 	$\gamma^{(k)}, \beta^{(k)}$: & Parameters optimized during Backpropagation
\end{tabular} ~\\

1. Normalize:
$$
	\hat s^{(k)} = \frac{s^{(k)} - \mathbb E[s^{(k)}]}{\sqrt{Var[s^{(k)}]}}
$$

2. Allow the network to change the range:
$$
	s'^{(k)}  = \gamma^{(k)} \hat s^{(k)} + \beta^{(k)}
$$

\subsubsection{Other Normalizations}
\begin{itemize}
	\item Layer Norm
	\item Instance Norm
	\item Group Norm
\end{itemize}



\subsubsection{Data Augmentation}
\begin{itemize}
	\item Classifier has to be invariant to a wide variety of transformations → Synthesize data simulating plausible transformations
	\iprops Training: Random Crops, Testing: Fixed Set of Crops
	\iprops Use same data augmentation when comparing two networks
	\iprops Consider data augmentation a part of your network design
	\item Augmentations:
	\begin{itemize}
		\item Flip
		\item Crop
		\item Brightness and contrast changes
		\item ... 
	\end{itemize}
\end{itemize}



\pagebreak
\section{Fully Connected Neural Network}
\subsection{Structure}

\textbf{Parameters}: ~\\
\begin{tabular}{ll}
	$x_k$: & Input variables \\
	$\theta = \{W,b\}$: & Model parameters \\
	$w_{i,j,k}$: & Network weights \\
	$b_{i,j}$: & Network biases \\
	& \begin{tabular}{ll}
		$i$: & Index of layer \\
		$j$: & Index of neuron in layer (neuron of next layer)\\
		$k$: & Index of weight in neuron (neuron of previous layer) \\
	\end{tabular} \\	
	$l$: & Depth: number of layers (All hidden and the output layer - no input layer)\\
	$m_i$: & Width: number of neurons in layer $i$ (Here: layer $0$ is the input layer)\\
	%$n$: & Number of weights in neuron \\
	$\hat y_i$: & Computed output/Prediction \\
	$y_i$: & Ground truth targets \\
	$\mathcal L(y, \hat y, \theta)$: & Loss function \\
	$a(s)$: & Activation function
\end{tabular} ~\\

\textbf{Graphical Representation}
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/nn.png}
\end{figure} ~\\

\textbf{Mathematical Representation}
$$
	L = \mathcal L(y_j, \hat y_j, \theta)
$$
$$
	\hat y_j = a(s_{l,j})
$$
$$
	h_{i,j} = a(s_{i,j})
$$
$$
	s_{i,j} = b_{i,j} + \sum_{k = 1}^{m_{i-1}} h_{i-1,k} ⋅ w_{i,j,k}
$$
$$
	s_{1,j} = b_{1,j} + \sum_{k = 1}^{m_0} x_k ⋅ w_{1,j,k}
$$

\subsection{Number of weights}
\begin{tabular}{ll}	
	$l$: & Depth: number of layers \\
	$m_i$: & Width: number of neurons in layer $i$ (Here: layer $0$ is the input layer)\\
	$a$ & Number of parameters of the activation functions
\end{tabular} ~\\

Number of weights is defined as:
$$
	a + \sum_{i = 1}^l m_i ⋅ m_{i-1} + m_i
$$

\subsection{Forward and Backward Pass}
\subsubsection{Forward Pass/ Forward Propagation}
Use formulas to calculate loss:
$$
	s_{1,1} = b_{1,1} + \sum_{k = 1}^{m_0} x_k ⋅ w_{1,1,k} \tab \dots \tab L = \mathcal L(y_j, \hat y_j, \theta)
$$

\subsection{Backward Pass/Backward Propagation}
\textbf{Weights of last layer:}
$$
	\frac{\partial L}{\partial w_{l,j,k}} = \frac{\partial L}{\partial \hat y_j} ⋅ \frac{\partial \hat y_j}{\partial s_{l,j}} ⋅ \frac{\partial s_{l,j}}{\partial w_{l,j,k}}
$$

\textbf{Weights of second last layer:}
$$
	\frac{\partial L}{\partial w_{l-1,j,k}} = \sum_{o = 1}^{m_l} \frac{\partial L}{\partial \hat y_o} ⋅ \frac{\partial \hat y_o}{\partial s_{l,o}} ⋅ \frac{\partial s_{l,o}}{\partial h_{l-1, j}} ⋅ \frac{\partial h_{l-1, j}}{\partial s_{l-1,j}} ⋅ \frac{\partial s_{l-1,j}}{\partial w_{l-1,j,k}}
$$

\textbf{General:}
$$
	\frac{\partial L}{\partial w_{i,j,k}} = \sum_{o_1 = 1}^{m_{i+1}} \dots \sum_{o_{l-i} = 1}^{m_l} \frac{\partial L}{\partial \hat y_{o_1}} ⋅ \frac{\partial \hat y_{o_1}}{\partial s_{l,o_1}} ~~⋅~~ \frac{\partial s_{l,o_1}}{\partial h_{l-1, o_2}} ⋅ \frac{\partial h_{l-1, o_2}}{\partial s_{l-1,o_2}} ⋅ \dots ⋅ \frac{\partial s_{i+1,o_{l-i}}}{\partial h_{i, j}} ⋅\frac{\partial h_{i, j}}{\partial s_{i,j}} ⋅ \frac{\partial s_{i,j}}{\partial w_{i,j,k}}
$$

\pagebreak

\section{Convolutional Neural Network}
\subsection{Advantages over FCNNs}
\textbf{Using deep networks:}
\begin{itemize}
	\item Fully Connected Neural Networks:
	\begin{itemize}
		\icons No structure
		\icons Just brute force
		\icons Optimization becomes hard
		\icons Performance plateaus/drops
	\end{itemize}
	\item Convolutional Neural Network
	\begin{itemize}
		\ipros Layers with structure
		\ipros Weight sharing (using the same weights for different parts of the image) 
	\end{itemize}
\end{itemize}

\subsection{2D - Convolution}
\subsubsection{General}
\begin{itemize}
	\item Stride = 1
	\item Padding = 0
\end{itemize}
\paragraph{Mathematical representation} ~\\

\textbf{Parameters:} \\
\begin{tabular}{ll}
	$x_{i,j,k}$: & Value of the pixel of the input image at position $i,j,k$ \\
	$w_{i,j,k}$: & Value of the pixel of the kernel at position $i,j,k$ \\
	$z_{i,j,k}$: & Value of the pixel of the output image (feature map) at position $i,j,k$ \\
	& \begin{tabular}{ll}
		$i$: & Index of channel \\
		$j$: & Index of height \\
		$k$: & Index of width
	\end{tabular} \\
	$C$: & Depth of the input image (number of channels) \\
	$H_i$: & Height of the input image (number of pixels (vertical)) \\
	$W_i$: & Width of the input image (number of pixels (horizontal)) \\
	$H_K$: & Height of the kernel \\
	$W_K$: & Width of the kernel \\
	$H_o$: & Height of the output image \\
	$W_o$: & Width of the output image \\
	$b_{j,k}$: & Bias at position $j,k$
\end{tabular} ~\\

\textbf{Input image:} \\
Image with the pixels: $x_{1,1,1}$ to $x_{C,H_i,W_i}$ \\

\textbf{Kernel:} \\
Filter image with the pixels: $w_{1,1,1}$ to $w_{C, H_K, W_K}$ \\

\textbf{Output image:} \\
Image with the pixels: $z_{1,1,1}$ to $z_{1, H_o, W_o}$ where:
$$
	z_{1,j,k} = b_{j,k} + \sum_{l = 1}^C \sum_{m = j}^{H_K + j - 1} \sum_{n = k}^{W_K + k - 1} w_{l,m-j+1,n-k+1} ⋅ x_{l,m,n}
$$
%$$
%	\begin{array}{l}		
%		\tab = w_{1,1,1} ⋅ x_{1,j,k} + \dots + w_{1,1, W_K} ⋅ x_{1,j,W_K + k - 1} + \\
%		\tab\tab \vdots \\
%		\tab + w_{1,H_K,1} ⋅ x_{1,H_K + j - 1,k} + \dots + w_{1,H_K, W_K} ⋅ x_{1,H_K + j - 1, W_K + k - 1} \\
%		\tab[3] \vdots \\
%		\tab w_{C,1,1} ⋅ x_{C,j,k} + \dots + w_{C,1, W_K} ⋅ x_{C,j,W_K + k - 1} + \\
%		\tab\tab \vdots \\
%		\tab + w_{C,H_K,1} ⋅ x_{C,H_K + j - 1,k} + \dots + w_{C,H_K, W_K} ⋅ x_{C,H_K + j - 1, W_K + k - 1} \\
%		\tab + b_{j,k}
%	\end{array}	
%$$

\paragraph{Graphical representation} ~\\
\renewcommand{\arraystretch}{2}
\textbf{Image:} \\
\begin{tabular}{ccc}
	Channel 1: & & Channel C: \\
	\begin{tabular}{|c|c|c|c|}
		\hline
		$x_{1,1,1}$ & $x_{1,1,2}$ & $\dots$ & $x_{1,1,W_i}$ \\
		\hline
		$x_{1,2,1}$ & $x_{1,2,2}$ & $\dots$ & $x_{1,2,W_i}$ \\
		\hline
		$\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$x_{1,H_i,1}$ & $x_{1,H_i,2}$ & $\dots$ & $x_{1,H_i,W_i}$ \\
		\hline
	\end{tabular}
	&
	$\dots$
	&
	\begin{tabular}{|c|c|c|c|}
		\hline
		$x_{C,1,1}$ & $x_{C,1,2}$ & $\dots$ & $x_{C,1,W_i}$ \\
		\hline
		$x_{C,2,1}$ & $x_{C,2,2}$ & $\dots$ & $x_{C,2,W_i}$ \\
		\hline
		$\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$x_{C,H_i,1}$ & $x_{C,H_i,2}$ & $\dots$ & $x_{C,H_i,W_i}$ \\
		\hline
	\end{tabular}
\end{tabular} ~\\


\textbf{Kernel:} \\
\begin{tabular}{ccc}
	Channel 1: & & Channel C: \\
	\begin{tabular}{|c|c|c|}
		\hline
		$w_{1,1,1}$ & $\dots$ & $w_{1,1,W_K}$ \\
		\hline
		$\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$w_{1,H_K,1}$ & $\dots$ & $w_{1,H_K,W_K}$ \\
		\hline
	\end{tabular}
	&
	$\dots$
	&
	\begin{tabular}{|c|c|c|}
		\hline
		$w_{C,1,1}$ & $\dots$ & $w_{C,1,W_K}$ \\
		\hline
		$\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$w_{C,H_K,1}$ & $\dots$ & $w_{C,H_K,W_K}$ \\
		\hline
	\end{tabular}
\end{tabular} ~\\

\textbf{Output image:} \\
\begin{tabular}{ccc}
	Channel 1: & &\\
	\begin{tabular}{|c|c|c|}
		\hline
		$z_{1,1,1}$ & $\dots$ & $z_{1,1,W_o}$ \\
		\hline
		$\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$z_{1,H_o,1}$ & $\dots$ & $z_{1,H_o,W_o}$ \\
		\hline
	\end{tabular}
	&
	&
\end{tabular}

\paragraph{Graphical Example} ~\\
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/conv2d_ex.png}
\end{figure}
\renewcommand{\arraystretch}{1}

\subsubsection{Stride}
\begin{itemize}
	\item Apply filter every S-th spatial location
	\iprops Must hold $(H_i - H_K) / S, (W_i - W_K) / S \in \mathbb N_0$
\end{itemize}

\textbf{Parameters:} ~\\
\begin{tabular}{ll}
	$z_{j,k}$: & Value of the pixel of the original output image (with stride 1) at position $j,k$ \\
	$z'_{j,k}$: & Value of the pixel of the output image with stride $S$ at position $j,k$ \\
	& \begin{tabular}{ll}
		$j$: & Index of height \\
		$k$: & Index of width \\
	\end{tabular} \\
	$H_i$: & Height of the original image (number of pixels (vertical)) \\
	$W_i$: & Width of the original input image (number of pixels (horizontal)) \\
	$H_o$: & Height of the new output image (number of pixels (vertical)) \\
	$W_o$: & Width of the new output image (number of pixels (horizontal)) \\
	$H_K$: & Height of the kernel \\
	$W_K$: & Width of the kernel \\
	$S$: & Stride \\
\end{tabular} ~\\

\textbf{Original output image:} \\
Original Output image with the pixels: $z_{1,1}$ to $z_{H_i,W_i}$ \\

\textbf{New output image:} \\
Output image with stride with the pixels: $z'_{1,1}$ to $z'_{H_o, W_o}$ where \\
$$
	z'_{j,k} = z_{2j-1,2k-1}
$$ and
$$
	H_o = \frac{H_i - 1}{S} + 1, \tab W_o = \frac{W_i - 1}{S} + 1
$$

\subsubsection{Padding}
\begin{itemize}
	\item Surround original input image with pixels with value $0$
	\iprops Allows the output image to have the same number of pixels as the input image
\end{itemize}

\paragraph{Mathematical representation} ~\\
\textbf{Parameters:} ~\\
\begin{tabular}{ll}
	$x_{i,j,k}$: & Value of the pixel of the original input image (with padding 0) at position $i,j,k$ \\
	$x'_{i,j,k}$: & Value of the pixel of the input image with Padding $P$ at position $i,j,k$ \\
	& \begin{tabular}{ll}
		$i$: & Index of channel \\
		$j$: & Index of height \\
		$k$: & Index of width \\
	\end{tabular} \\
	$C_i$: & Depth of the input image (number of channels) \\
	$H_i$: & Height of the original image (number of pixels (vertical)) \\
	$W_i$: & Width of the original input image (number of pixels (horizontal)) \\
	$H_o$: & Height of the new input image (number of pixels (vertical)) \\
	$W_o$: & Width of the new input image (number of pixels (horizontal)) \\
	$P$: & Padding \\
\end{tabular} ~\\

\textbf{Original input image:} \\
Original input image with the pixels: $x_{1,1,1}$ to $z_{C,H_i,W_i}$ \\

\textbf{New input image:} \\
Input image with padding with the pixels: $x'_{1,1,1}$ to $z'_{C, H_o, W_o}$ where \\
$$
	x'_{i,j,k} = \begin{cases}
		x_{i, j - P, k - P} & \text{for } P < j ≤ j + P, P < k ≤ k + P \\
		0 & \text{sonst}
	\end{cases}
$$ and
$$
	H_o = H_i + 2 ⋅ P, \tab W_o = W_i + 2 ⋅ P
$$

\paragraph{Graphical representation for P = 1} ~\\
\renewcommand{\arraystretch}{2}
\textbf{Original input image:} \\
\begin{tabular}{ccc}
	Channel 1: & & Channel C: \\
	\begin{tabular}{|c|c|c|}
		\hline
		$x_{1,1,1}$ & $\dots$ & $x_{1,1,W_K}$ \\
		\hline
		$\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$x_{1,H_K,1}$ & $\dots$ & $x_{1,H_K,W_K}$ \\
		\hline
	\end{tabular}
	&
	$\dots$
	&
	\begin{tabular}{|c|c|c|}
		\hline
		$x_{C,1,1}$ & $\dots$ & $x_{C,1,W_i}$ \\
		\hline
		$\vdots$ & $\ddots$ & $\vdots$ \\
		\hline
		$x_{C,H_i,1}$ & $\dots$ & $x_{C,H_i,W_i}$ \\
		\hline
	\end{tabular}
\end{tabular} ~\\


\textbf{New input image:} \\
\begin{tabular}{ccc}
	Channel 1: & & Channel C: \\
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		$0$ & $0$ & $\dots$ & $0$ & $0$ \\
		\hline
		$0$ & $x_{1,1,1}$ & $\dots$ & $x_{1,1,W_i}$ & $0$ \\
		\hline
		$\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ \\
		\hline
		$0$ & $x_{1,H_i,1}$ & $\dots$ & $x_{1,H_i,W_i}$ & $0$ \\
		\hline
		$0$ & $0$ & $\dots$ & $0$ & $0$ \\
		\hline
	\end{tabular}
	&
	$\dots$
	&
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		$0$ & $0$ & $\dots$ & $0$ & $0$ \\
		\hline
		$0$ & $x_{C,1,1}$ & $\dots$ & $x_{C,1,W_K}$ & $0$ \\
		\hline
		$\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ \\
		\hline
		$0$ & $x_{C,H_K,1}$ & $\dots$ & $x_{C,H_K,W_K}$ & $0$ \\
		\hline
		$0$ & $0$ & $\dots$ & $0$ & $0$ \\
		\hline
	\end{tabular}
\end{tabular} ~\\
\renewcommand{\arraystretch}{1}





\subsection{Convolution Layer}
\begin{itemize}
	\item Contains several filters of size $C_i * H_K * W_K$
	\item Output image is the concatenations of the images generated by a 2D-Convolution with each filter
	\iprops Each filter captures a different image characteristics
	\iprops Numer of output channels is equal to the number of filters
	\iprops Filter values are learnable by the network	
	\iprops Feature Extraction: Computes a feature in a given region
\end{itemize}

\subsubsection{Mathematical representation}
\textbf{Parameters:} \\
\begin{tabular}{ll}
	$x_{i,j,k}$: & Value of the pixel of the input image at position $i,j,k$ \\
	$w_{i,o,j,k}$: & Value of the pixel of the kernel at position $i,o,j,k$ \\
	$z_{i,j,k}$: & Value of the pixel of the output image at position $i,j,k$ \\
	& \begin{tabular}{ll}
		$i$: & Index of channel \\
		$j$: & Index of height \\
		$k$: & Index of width \\
		$o$: & Index of the filters
	\end{tabular} \\
	$C_i$: & Depth of the input image (number of channels) \\
	$H_i$: & Height of the input image (number of pixels (vertical)) \\
	$W_i$: & Width of the input image (number of pixels (horizontal)) \\
	$H_K$: & Height of the kernel \\
	$W_K$: & Width of the kernel \\
	$C_o$: & Depth of the output image \\
	$H_o$: & Height of the output image \\
	$W_o$: & Width of the output image \\
	$b_{j,k}$: & Bias at position $j,k$ \\
	$S$: & Stride \\
	$P$: & Padding
\end{tabular} ~\\

\textbf{Input image:} \\
Image with the pixels: $x_{1,1,1}$ to $x_{C,H_i,W_i}$ \\

\textbf{Kernel:} \\
Weight tensor with the pixels: $w_{1,1,1,1}$ to $w_{C_i, C_o, H_K, W_K}$ where
$w_{1,o,1,1}$ to $w_{C_i, o, H_K, W_K}$ is the $o$-th filter image \\

\textbf{Output image:} \\
Image with the pixels: $z_{1,1,1}$ to $z_{C_o, H_o, W_o}$ where:
$$
	z_{i,j,k} = b_{j,k} + \sum_{l = 1}^{C_i} \sum_{m = j}^{H_K + j - 1} \sum_{n = k}^{W_K + k - 1} w_{l,i,m-j+1,n-k+1} ⋅ x_{l,m,n}
$$

\subsubsection{Output dimension}

\textbf{Output dimensions:} ~\\
$$
	H_o = \left(\left\lfloor \frac{H_i + 2 ⋅ P - H_K}{S} \right\rfloor + 1\right)
$$
$$
	W_o = \left(\left\lfloor \frac{W_i + 2 ⋅ P - W_K}{S} \right\rfloor + 1\right)
$$

\textbf{Output dimension for $N = H_i = W_i$ and $F = H_K = W_K$ (default):}
$$
	\left(\left\lfloor \frac{N + 2 ⋅ P - F}{S} \right\rfloor + 1\right) \times \left(\left\lfloor \frac{N + 2 ⋅ P - F}{S} \right\rfloor + 1\right)
$$

\subsubsection{Number of parameters}
$$
	\text{number of parameters} = (C_i ⋅ H_K ⋅ W_K + 1) ⋅ C_o
$$

\subsubsection{Types of convolutions}
	\textbf{Valid convolution:} \\
	$$
		P = 0
	$$
	
	\textbf{Same convolution:} \\
	Output size = input size:
	$$
		P = (F - 1) / 2
	$$ where
	$F = H_K = W_K$ (filter size) \\
	
	\textbf{$1 \times 1$ Convolution:} \\
	\begin{itemize}
		\item Keeps the dimension and scales the input
		\iprops Same as having a fully connected layer with $C$ number of neurons
		\iprops Used to shrink the number of channels
		\iprops Adds a non-linearity
	\end{itemize}	
	$$
		F = H_K = W_K = 1
	$$
	
\subsection{Pooling Layer}
\begin{itemize}
	\iprops Common used to shrink size of the image
	\iprops Feature Selection: Picks the strongest activation in a region
\end{itemize}

\textbf{Parameters:} \\
\begin{tabular}{ll}
	$x_{i,j,k}$: & Value of the pixel of the input image at position $i,j,k$ \\
	$z_{i,j,k}$: & Value of the pixel of the output image at position $i,j,k$ \\
	& \begin{tabular}{ll}
		$i$: & Index of channel \\
		$j$: & Index of height \\
		$k$: & Index of width \\
	\end{tabular} \\
	$C_i$: & Depth of the input image (number of channels) \\
	$H_i$: & Height of the input image (number of pixels (vertical)) \\
	$W_i$: & Width of the input image (number of pixels (horizontal)) \\
	$H_K$: & Height of the kernel \\
	$W_K$: & Width of the kernel \\
	$C_o$: & Depth of the output image (number of channels) \\
	$H_o$: & Height of the output image \\
	$W_o$: & Width of the output image \\
	$S$: & Stride \\
	$F = H_K = W_K$: & Filter size (if $H_K = W_K$)
\end{tabular} ~\\

\subsubsection{Output dimension:}
$$
	C_o = C_i
$$
$$
	H_o = \frac{H_i - H_K}{S} + 1
$$
$$
	W_o = \frac{W_i - H_K}{S} + 1
$$


\subsubsection{Max Pooling}
\begin{itemize}
	\item Takes the maximum value of a region in the input image
	\iprops Common settings: $F = 2, S = 2$ or $F = 3, S = 2$
\end{itemize} ~\\

\textbf{Input image:} \\
Image with the pixels: $x_{1,1,1}$ to $x_{C_i,H_i,W_i}$ \\

\textbf{Output image:} \\
Image with the pixels: $z_{1,1,1}$ to $z_{C_o, H_o, W_o}$ where:
$$
	z_{i,j,k} = \max (x_{i,j,k}, \dots, x_{i,j,W_K + k - 1}, \dots, x_{i,H_K + j - 1,k}, \dots, x_{i,H_K + j - 1, W_K + k - 1})
$$

\subsubsection{Average Pooling}
\begin{itemize}
	\item Takes the average value of a region in the input image
	\iprops Common settings: $F = 2, S = 2$ or $F = 3, S = 2$
	\iprops Typically used deeper in the network
\end{itemize}

\textbf{Input image:} \\
Image with the pixels: $x_{1,1,1}$ to $x_{C_i,H_i,W_i}$ \\

\textbf{Output image:} \\
Image with the pixels: $z_{1,1,1}$ to $z_{C_o, H_o, W_o}$ where:
$$
	z_{i,j,k} = (x_{i,j,k} + \dots + x_{i,j,W_K + k - 1} + \dots + x_{i,H_K + j - 1,k} + \dots + x_{i,H_K + j - 1, W_K + k - 1}) / H_K ⋅ W_K
$$

\subsection{Skip Connections}
\begin{itemize}
	\item Problems with deeper networks:
	\begin{itemize}
		\item Training becomes harder
		\item Vanishing gradients
	\end{itemize}
	\item Add an output to an output of a later layer
	\iprops Requires same dimension → Same convolutions are often used
	\iprops Guaranteed it will not hurt performance, can only improve
\end{itemize}

\subsubsection{Mathematical Representation}
\textbf{Parameters:} \\
\begin{tabular}{ll}
	$z^L$: & Output of layer $L$ \\
	$W^L$: & Weight Tensor of layer $L$ (Values of the filter) \\
	$b^L$: & Bias of layer $L$ \\
	$a(x)$: & Activation function
\end{tabular}

e.g. \\
$$
	z^{L + 1} = a(W^{L + 1} x^L + b^{L + 1} + x^{L - 1})
$$

\subsubsection{Graphical Representation}
\begin{figure}[H]
	\includegraphics[width=0.5\columnwidth]{figures/res_block.png}
\end{figure}

\subsection{Inception Layer}
\begin{itemize}
	\item Uses several convolution layers and concatenates them afterwards
	\item Uses $1 \times 1$ convolutions beforehand to shrink the channel size 
	\iprops Used are same convolutions to keep the dimensions
\end{itemize}

Example: \\
\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/inception_layer.png}
\end{figure}

\subsection{Xception Net (Extreme Version of Inception)}
\begin{itemize}
	\item Filters are applied only at certain depths of the features
	\item It is followed by a $1 \times 1$ convolution to shrink the channel size to $1$
	\ipros Requires less computations
\end{itemize}

Example: \\
\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/xception_net.png}
\end{figure}




\subsection{ConvNet}
\begin{itemize}
	\item Is a concatenation of Conv Layers and activations
\end{itemize}

\subsubsection{Typically network architecture}
\begin{itemize}
	\item[] \begin{itemize}
		\item[] \begin{itemize}
			\item Convolution Layer
			\item Activation Function
			\item[] \tab $\vdots$
			\item Convolution Layer
			\item Activation Function
		\end{itemize}
		\item Pool Layer
		\item[] \tab $\vdots$
		\begin{itemize}
			\item Convolution Layer
			\item Activation Function
			\item[] \tab $\vdots$
			\item Convolution Layer
			\item Activation Function
		\end{itemize}
		\item Pool Layer
	\end{itemize}
	\item 1 or 2 Fully Connected Layer
\end{itemize}

\subsection{Classic Architectures}
\subsubsection{LeNet}
\begin{itemize}
	\iprops $\sim 60k$ parameters
	\iprops Use of tanh/sigmoid activations
\end{itemize}
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/lenet.png}
\end{figure}

\subsubsection{AlexNet}
\begin{itemize}
	\iprops $\sim 60M$ parameters
	\iprops Use of ReLU activations
\end{itemize}
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/alexnet.png}
\end{figure}

\subsubsection{VGGNet}
\begin{itemize}
	\iprops Use of $3 \times 3$ Same convolution layers
	\iprops Use of $2 \times 2$ MaxPool Layers
	\iprops Large but simplicity makes it appealing
	\iprops E.g. VGG-16: 16 layers with $138M$ parameters
\end{itemize}
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/vggnet.png}
\end{figure}

\subsubsection{ResNet}
\begin{itemize}
	\item Uses Skip Connections
	\iprops E.g. ResNet-152: $60M$ parameters
\end{itemize}
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/resnet.png}
\end{figure}

\subsection{Fully Convolutional Network}
\subsubsection{Types of Upsampling}
\textbf{Interpolation}
\begin{itemize}
	\item Nearest neighbor interpolation
	\item Bilinear interpolation
	\item Bicubic interpolation
\end{itemize}

\textbf{Transposed Convolution (Up-convolution)} \\
Is built of the following layers:
\begin{enumerate}
	\item Unpooling
	\item Convolution
\end{enumerate}

\subsubsection{U-Net}
\begin{itemize}
	\item Is built of an encoder and a decoder
	\iprops Uses skip connections
	\iprops Is an autoencoder
\end{itemize}
\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/u-net.png}
\end{figure}

\textbf{Encoder:}
\begin{itemize}
	\item Left side: Contradiction Path
	\item Architecture:
	\begin{itemize}
		\item Repeated several times:
		\begin{enumerate}
			\item Unpadded $3 \times 3$ convolutions
			\item ReLU activation
			\item Unpadded $3 \times 3$ convolutions
			\item ReLU activation
			\item $2 \times 2$ maxpooling operation with stride 2
		\end{enumerate}
		\item At each downsampling step: number of channels is doubled		
	\end{itemize}
	\iprops Captures context of the image
\end{itemize} ~\\

\textbf{Decoder:}
\begin{itemize}
	\item Right side: Expansion Path
	\item Architecture:
	\begin{itemize}
		\item Repeated several times:
		\begin{enumerate}
			\item $2 \times 2$ up-convolution
			\item Concatenation of skip connections
			\item Unpadded $3 \times 3$ convolutions
			\item ReLU activation
			\item Unpadded $3 \times 3$ convolutions
			\item ReLU activation
		\end{enumerate}
		\item Final layer: $1 \times 1$ convolution layer to map the channels to classes		
	\end{itemize}
	\iprops Upsampling to recover spatial locations for assigning class labels to each pixel
\end{itemize}
	
\pagebreak
\section{Recurrent Neural Networks (RNN)}
\begin{itemize}
	\item Processes sequence data
	\item Input/output can be sequences
	\iprops Properties of the eigenvalues of $\theta_c$
	\begin{itemize}
		\item $|\lambda| < 1$: Vanishing gradient
		\item $|\lambda| > 1$: Exploding gradient
	\end{itemize}
	\iprops Simple RNN uses tanh as activation function
\end{itemize}

\subsection{Structure}
\textbf{Graphical Representation of a Multi-layer RNN}
\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/rnn.png}
\end{figure}

\subsection{Structure of one neuron}
\textbf{Parameters:} \\
\begin{tabular}{ll}
	$x_t$: & Input at time $t$ \\
	$\theta_c, \theta_x, \theta_h$: & Learnable parameters (time-independent) \\
	$A_t$: & Hidden state at time $t$ \\
	$A_{t-1}$: & Previous hidden state (at time $t-1$) \\
	$h_t$: & Output at time $t$
\end{tabular}

\textbf{Mathematical Representation:}
$$
	A_t = \theta_c A_{t-1} + \theta_x x_t
$$
$$
	h_t = \theta_h A_t
$$

\textbf{Graphical Representation:}
\begin{figure}[H]
	\includegraphics[width=0.3\columnwidth]{figures/rnn_neuron.png}
\end{figure}

\subsection{Long-Short Term Memory (LSTM)}
\begin{itemize}
	\iprops Fixed defined dimensions, i.e. $x_t, h_t \in \mathbb R^{n_1 \times \dots \times n_m}  ~\forall t$ with fixed $n_1, \dots, n_m$
	\iprops Gate:
	\begin{itemize}
		\item Removes or add information to the cell
		\item Is a multiplication with a sigmoid function
	\end{itemize}
	\iprops Cell prevents vanishing gradients
\end{itemize}

\textbf{Parameters:} \\
\begin{tabular}{ll}
	$x_t$: & Input at time $t$ \\
	$\theta_{xf}, \dots, \theta_{xg},\theta_{hf}, \dots, \theta_{hg}$: & Weights \\
	$b_f, \dots, b_g$: & Biases \\
	$\circ : \mathbb R^{n_1 \times \dots \times n_m} \times \mathbb R^{n_1 \times \dots \times n_m} → \mathbb R^{n_1 \times \dots \times n_m}$: & Element-wise tensor-multiplication
\end{tabular}

\textbf{Graphical Representation:}
\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/lstm_3.png}
\end{figure}

\textbf{Mathematical Representation:} \\
Forget gate: Decides when to erase the cell state ($f_t = 0$: forget, $f_t = 1$: keep)
$$
	f_t = \sigma(\theta_{xf} x_t + \theta_{hf} h_{t-1} + b_f)
$$
Input gate: Decides which values will be updated
$$
	i_t = \sigma(\theta_{xi} x_t + \theta_{hi} h_{t-1} + b_i)
$$
Output gate: Decides which values will be outputted
$$
	o_t = \sigma(\theta_{xo} x_t + \theta_{ho} h_{t-1} + b_o)
$$
Cell Update:
$$
	g_t = \tanh(\theta_{xg} x_t + \theta_{hg} h_{t-1} + b_g)
$$
Cell: Transports the information through the unit
$$
	C_t = f_t \circ C_{t-1} + i_t \circ g_t
$$
Output:
$$
	h_t = o_t \circ \tanh(C_t)
$$





\pagebreak
\section{Training}
\subsection{Learning}
\begin{itemize}
	\item Learning means generalization to unknown dataset, i.e. train on known dataset, test with optimized parameters on unknown dataset
\end{itemize}

\subsection{Dataset}
\begin{itemize}
	\item Split dataset into
	\begin{itemize}
		\item Training set (e.g. 60\%, 80\%) - Used to train the neural network
		\item Validation set (e.g. 20\%, 10\%) - Validate the current model to find the best hyperparameters
		\item Test set (e.g. 20\%, 10\%) - Is only used once in the end
	\end{itemize}
\end{itemize}

\subsection{Obtaining the model}
\begin{enumerate}
	\item Estimating using current model
	\item Calculating loss
	\item Optimizing the model
\end{enumerate}

\subsection{Weight initialization}
\textbf{Bad choice:}
\begin{itemize}
	\item All weights $= 0$ → No symmetry breaking
	\item Small Random Numbers → Output becomes zero using tanh as activation function → Vanishing gradient
	\item Big Random Numbers → Output saturates to $-1$ and $1$ using tanh as activation function → Vanishing gradient
\end{itemize}

\subsubsection{Xavier Initialization}
\begin{itemize}
	\item Gaussian with zero mean and $Var(w) = \frac 1 n$ ($n$: number of input neurons)
	\item For ReLU: $Var(w) = \frac 2 n$
\end{itemize}

\subsection{Errors}
\begin{itemize}
	\item Ground truth error
	\begin{itemize}
		\item Faults in dataset, e.g. wrong classification of sample image
		\item Underfitting
	\end{itemize}
	\item Training set error
	\begin{itemize}
		\item Underfitting
	\end{itemize}
	\item Validation/test set error
	\begin{itemize}
		\item Overfitting
	\end{itemize}
\end{itemize}

\subsection{Hyperparameters}
\begin{itemize}
	\item Hyperparameters = Learning Setup + Optimization, i.e.,
	\begin{itemize}
		\item Network architecture (number of layers, number of weights, ...)
		\item Number of iterations
		\item Learning rate(s)
		\item Regularization
		\item Batch size
		\item ...
	\end{itemize}
\end{itemize}

\subsubsection{Hyperparameter Tuning Methods}
\begin{itemize}
	\item Manual search:
	\begin{itemize}
		\item Find out the optimal hyperparameters manually
		\item Most common
	\end{itemize}
	\item Grid search:
	\begin{itemize}
		\item Define ranges for all parameters spaces and select points
		\item Iterates over all possible configurations
	\end{itemize}
	\item Random search:
	\begin{itemize}
		\item Like grid search but one picks points at random in the predefined ranges
	\end{itemize}
\end{itemize}

\subsection{Learning Curves}
\subsubsection{Ideal Training}
\begin{itemize}
	\item Small gap between training and validation loss
	\item Training and validation loss go down at the same rate (stable without fluctuations)
\end{itemize}

Example:
\begin{figure}[H]
	\includegraphics[width=\columnwidth]{figures/l_curves.png}
\end{figure}

\subsubsection{Underfitting}
\begin{itemize}
	\item Training and validation losses decreases even at the end of training
	\iprops Reasons:
	\begin{itemize}
		\item Model is still learning
	\end{itemize}
\end{itemize}

Example:
\begin{figure}[H]
	\includegraphics[width=0.5\columnwidth]{figures/graph_underfitting.png}
\end{figure}

\subsubsection{Overfitting}
\begin{itemize}
	\item Training loss decreases and validation loss increases
	\iprops Reasons:
	\begin{itemize}
		\item Model is memorizing the training samples instead of generalizing
	\end{itemize}
\end{itemize}

Example:
\begin{figure}[H]
	\includegraphics[width=0.5\columnwidth]{figures/graph_overfitting.png}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/graph_underOverfitting.png}
\end{figure}

\subsubsection{Other Examples}
\textbf{Validation set easier than training set:}
\begin{itemize}
	\item Validation loss is lower than training loss
	\iprops Reasons:
	\begin{itemize}
		\item Validation set is easier than the training set
		\item Bug in the implementation
	\end{itemize}
\end{itemize}

Example:
\begin{figure}[H]
	\includegraphics[width=0.5\columnwidth]{figures/graph_val_easy.png}
\end{figure}

\textbf{Learning rate to low:}
\begin{itemize}
	\item Loss curves decrease almost linearly
	\iprops Reasons:
	\begin{itemize}
		\item The initial Learning rate is too low
	\end{itemize}
\end{itemize}

Example:
\begin{figure}[H]
	\includegraphics[width=0.5\columnwidth]{figures/graph_lr_low.png}
\end{figure}

\textbf{Learning rate to high:}
\begin{itemize}
	\item Loss curves decrease very quickly at the beginning and then remain on plateaus
	\iprops Reasons:
	\begin{itemize}
		\item Learning rate is too big
		\item Inconsistent dataset
	\end{itemize}
\end{itemize}

Example:
\begin{figure}[H]
	\includegraphics[width=0.5\columnwidth]{figures/graph_lr_high.png}
\end{figure}

\subsection{How To}
\subsubsection{Network Architecture}
\begin{itemize}
	\item Start with the simplest network possible
\end{itemize}
\subsubsection{Training samples}
\begin{enumerate}
	\item Start with a single training sample
	\begin{itemize}
		\item Check if output is correct
		\item Should overfit
		\item Train accuracy should be 100\%
	\end{itemize}
	\item Increase to handful of samples (e.g., 4)
	\begin{itemize}
		\item Check if input is handled correctly
	\end{itemize}
	\item Move to more samples
	\begin{itemize}
		\item 5, 10, 100, 1000, ...
		\item At some point, you should see generalization
	\end{itemize}
\end{enumerate}

\subsubsection{Learning rate}
\begin{itemize}
	\item Find a learning rate that makes the loss drop significantly within 100 iterations
	\item Good learning rates to try: $1e-1, 1e-2, 1e-3, 1e-4$
	\item Good weight decay to try: $1e-4, 1e-5, 0$
	\item Use Grid/Random search
\end{itemize}

\subsubsection{Timings}
\begin{itemize}
	\item Measure how long each iteration takes (should be $< 500 ms$)
	\item Look for bottlenecks (e.g. Dataloading, Backpropagation)
	\item Estimate total time
\end{itemize}


\subsubsection{Basic Recipe}
\begin{figure}[H]
	\includegraphics[width=0.7\columnwidth]{figures/recipe.png}
\end{figure}

\subsubsection{Bad Signs}
\begin{itemize}
	\item Training error not going down
	\item Validation error not going down
	\item Performance on validation better than on training set
	\item Tests on train set different than during training
\end{itemize}

\subsubsection{Good/Bad Practice}
\textbf{Good Practice:}
\begin{itemize}
	\item Use train/validation/test curves
	\begin{itemize}
		\item Evaluation needs to be consistent
		\item Numbers need to be comparable
	\end{itemize}
	\item Only make one change at a time
\end{itemize}

\textbf{Bad Practice/Common Mistakes}
\begin{itemize}
	\item Using single batch, it did not overfit
	\item Forgot to toggle train/eval mode for network
	\item Forgot to call \lstinline|.zero_grad()| (in PyTorch) before calling \lstinline|.backward()|
	\item Passed softmaxed outputs to a loss function that expects raw logits
	\item Training set contains test data
	\item Debug algorithm on test data
\end{itemize}


\pagebreak
\section{Transfer Learning}
\begin{itemize}
	\item Reuse parts of already trained models to train a new model
	\item Transfer Learning makes sense when
	\begin{itemize}
		\item task 1 (old task) and 2 (new task) have the same input
		\item you have more data for task 1 than for task 2
		\item the low-level features for task 1 could be useful to learn task 2
	\end{itemize}
\end{itemize}

\begin{figure}[H]
	\includegraphics[width=0.8\columnwidth]{figures/transfer_learning.png}
	\caption*{Left: Already trained model, Right: New model}
\end{figure}










\pagebreak
\section*{Notes}
This is a summary of the lecture~\lecture~of the Technical University Munich.
This lecture was presented by~\lecturer~in the~\semseter.
This summary was created by Gaida B.
All provided information is without guarantee.


%\section*{References}
%author. \textit{title}. publisher. location, year, 

\end{document}

%TODO check for todos








